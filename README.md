# ğŸš€ Multithreaded Web Server in C++17

A high-performance multithreaded web server built in C++17 using POSIX sockets, a thread pool, and asynchronous logging. Designed to handle multiple concurrent connections efficiently and serve static HTML content.

---

## ğŸ“ Project Structure
```
.
â”œâ”€â”€ include/         # ThreadPool and Logger headers
â”œâ”€â”€ src/             # Server source code
â”œâ”€â”€ static/          # HTML files served (index.html)
â”œâ”€â”€ logs/            # Server request logs
â”œâ”€â”€ test/            # ApacheBench benchmarking script
â”œâ”€â”€ scripts/         # Python plotting script
â”œâ”€â”€ results/         # Benchmark results and graph
â”œâ”€â”€ Makefile         # Build instructions
â”œâ”€â”€ README.md        # Project overview and usage
```

---

## âš™ï¸ Build & Run

### ğŸ“¦ Requirements:
- g++ (C++17)
- make
- ab (ApacheBench)
- Python3 + matplotlib + pandas

### ğŸ”¨ Build Server:
```bash
make
```

### â–¶ï¸ Run Server:
```bash
./server
```
---

## ğŸ§ª Benchmark with ApacheBench

### ğŸ“Š Run Benchmark Script:
```bash
chmod +x test/performance_test.sh
./test/performance_test.sh
```
This will:
- Run tests with concurrency levels [10, 50, 100, 200]
- Send 1000 requests per level
- Save metrics to `results/performance.csv`

### ğŸ“ˆ Plot Graph:
```bash
python3 scripts/plot_results.py
```
Generates: `results/graph.png`

---

## ğŸ“ˆ Sample Output Table (CSV)
| Concurrency | Requests | Requests/sec | Avg Time/request (ms) |
|-------------|----------|---------------|------------------------|
| 10          | 1000     | 310.82        | 32.17                  |
| 50          | 1000     | 301.14        | 166.04                 |
| 100         | 1000     | 319.07        | 313.41                 |
| 200         | 1000     | 326.60        | 612.37                 |

---

## ğŸ§  Features
- âœ… POSIX socket programming
- âœ… Fixed-size thread pool
- âœ… Thread-safe logging to `logs/server.log`
- âœ… Serves static HTML from `static/`
- âœ… Performance-tested with ApacheBench

---

## ğŸ“„ Performance Highlights
- **Peak Throughput:** ~326 requests/sec @ 200 clients
- **Avg Response Time:** ~32 ms under 10-client load
- **Scales up to 200 concurrent clients with ~600ms latency**

---

## ğŸ§‘â€ğŸ’» Author
**Mihir Patel**  